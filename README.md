# ğŸ”¢ Linear Regression â€” Scratch to Scikit-learn

This project demonstrates **Linear Regression** using three different methods:

1. âœ… **Scikit-learn** â€” library-based implementation  
2. ğŸ”§ **Gradient Descent** â€” iterative method, implemented from scratch  
3. ğŸ§® **Least Squares** â€” closed-form analytical solution  

We use a **synthetic dataset** generated from the equation:

> ğŸ§¾ `y = 2.5x + 5 + noise`

---

## ğŸ“ Project Structure

<pre>
linear-regression-three-ways/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv              # Generated synthetic dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sklearn_model.py         # Linear regression using Scikit-learn
â”‚   â”œâ”€â”€ gradient_descent.py      # Linear regression using gradient descent (from scratch)
â”‚   â””â”€â”€ least_squares.py         # Linear regression using least squares (analytical method)
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ regression_sklearn.png           # Plot of scikit-learn model
â”‚   â”œâ”€â”€ regression_gradient_descent.png # Plot of gradient descent model
â”‚   â””â”€â”€ regression_least_squares.png     # Plot of least squares model
â”œâ”€â”€ generate_data.py             # Script to generate synthetic dataset
â”œâ”€â”€ main.py                      # Runs all models, prints results, and saves plots
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
</pre>

---

## âš™ï¸ How to Install and Run

### 1. Clone the repository
```bash
git clone https://github.com/your-username/linear-regression-three-ways.git
cd linear-regression-three-ways
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Generate the dataset
```bash
python generate_data.py
```

### 4. Run the models
```bash
python main.py
```

---

## ğŸ§  Explanation of the Three Methods

| Method           | Description                                                                 |
|------------------|-----------------------------------------------------------------------------|
| **Scikit-learn** | Uses `LinearRegression` from the `sklearn.linear_model` module.            |
| **Gradient Descent** | Iteratively minimizes Mean Squared Error (MSE) using manual updates to weights and bias. |
| **Least Squares** | Uses matrix algebra to solve for the best-fit line in one step (analytical). |

---

## ğŸ“Š Example Output

After running `main.py`, youâ€™ll see output like:
```bash
ğŸ” Model Results:
Scikit-learn     â†’ w = 2.49, b = 4.98, MSE = 2.91
Gradient Descent â†’ w = 2.48, b = 4.99, MSE = 2.94
Least Squares    â†’ w = 2.49, b = 4.98, MSE = 2.91
```

---

## ğŸ–¼ï¸ Model Plots

Each model produces a visualization showing the fitted regression line over the data:

| Scikit-learn | Gradient Descent | Least Squares |
|--------------|------------------|----------------|
| ![Scikit-learn](plots/regression_scikit-learn.png) | ![Gradient Descent](plots/regression_gradient_descent.png) | ![Least Squares](plots/regression_least_squares.png) |

These plots help visualize how well each method fits the data. Despite using different approaches, all three produce very similar results because the data is linear and noise is minimal.

---

## ğŸš€ Future Enhancements

Here are some ideas for improving and expanding the project:

- ğŸ“‰ **Residual Plots**: Visualize the prediction errors (residuals) for deeper insights.
- ğŸ“ˆ **Multivariate Linear Regression**: Extend the current setup to handle multiple features.
- ğŸ  **Real-World Datasets**: Apply the models to real datasets like the California Housing dataset.
- â±ï¸ **Performance Metrics**: Compare training times or convergence steps (especially for gradient descent).
- ğŸ§ª **Regularization**: Add L1/L2 regularized versions of gradient descent.

---

## ğŸ™‹â€â™‚ï¸ Why I Built This

As a beginner, I wanted to understand Linear Regression deeply, not just use libraries. This project helped me learn:
- How regression works mathematically
- How to write and compare different implementations
- How to organize a machine learning project

---

ğŸ§  *This project is intentionally beginner-friendly â€” ideal for learning how linear regression works both mathematically and in practice with libraries.*

---