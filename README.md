# ğŸ”¢ Linear Regression â€” Scratch to Scikit-learn

This project demonstrates **Linear Regression** using three different methods:

1. âœ… **Scikit-learn** â€” library-based implementation  
2. ğŸ”§ **Gradient Descent** â€” iterative method, implemented from scratch  
3. ğŸ§® **Least Squares** â€” closed-form analytical solution  

We use a **synthetic dataset** generated from the equation:

> ğŸ§¾ `y = 2.5x + 5 + noise`

---

## ğŸ“ Project Structure

<pre>
linear-regression-three-ways/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ dataset.csv              # Generated synthetic dataset
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ sklearn_model.py         # Linear regression using Scikit-learn
â”‚   â”œâ”€â”€ gradient_descent.py      # Linear regression using gradient descent (from scratch)
â”‚   â””â”€â”€ least_squares.py         # Linear regression using least squares (analytical method)
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ regression_sklearn.png           # Plot of scikit-learn model
â”‚   â”œâ”€â”€ regression_gradient_descent.png # Plot of gradient descent model
â”‚   â””â”€â”€ regression_least_squares.png     # Plot of least squares model
â”œâ”€â”€ generate_data.py             # Script to generate synthetic dataset
â”œâ”€â”€ main.py                      # Runs all models, prints results, and saves plots
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # Project documentation
</pre>

---

## âš™ï¸ How to Install and Run

### 1. Clone the repository
```bash
git clone https://github.com/your-username/linear-regression-three-ways.git
cd linear-regression-three-ways

### 2. Install dependencies
```bash
pip install -r requirements.txt

### 3. Generate the dataset
```bash
python generate_data.py

### 4. Run the models
```bash
python main.py

## ğŸ§  Explanation of the Three Methods

<table>
  <tr>
    <th>Method</th>
    <th>Description</th>
  </tr>
  <tr>
    <td><strong>Scikit-learn</strong></td>
    <td>Uses <code>LinearRegression</code> from the <code>sklearn.linear_model</code> module.</td>
  </tr>
  <tr>
    <td><strong>Gradient Descent</strong></td>
    <td>Iteratively minimizes Mean Squared Error (MSE) using manual updates to weights and bias.</td>
  </tr>
  <tr>
    <td><strong>Least Squares</strong></td>
    <td>Uses matrix algebra to solve for the best-fit line in one step (analytical).</td>
  </tr>
</table>